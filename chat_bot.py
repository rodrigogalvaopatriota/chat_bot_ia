
#https://docs.haystack.deepset.ai/docs/huggingfacelocalgenerator


import streamlit as st
#from transformers import pipeline


class Oracle:
    

    def __init__(self):

        pass
        
    
    
    
    def contexto(self):
        with open('contexto.json', 'r') as file:
            contexto_file = file.read()
            
        #from transformers import AutoTokenizer

        #model_name = "valhalla/longformer-base-4096-finetuned-squadv1"
        #tokenizer = AutoTokenizer.from_pretrained(model_name)
        # contexto ruim
        contexto = """
            
                        'A Icomom √© uma empresa que presta servi√ßo na √°rea de telecomunica√ß√µes.'
                        'A icomon presta servi√ßos para estas empresas: Vtal, Oi, Vivo.'
                        'o campo macro atividades possuem estes valores: INST-FTTH, MUD-FTTH,REP-FTTH, RET-FTTH.'
                        'o campo estado possuem estes valores: Atrib√∫ido, Conclu√≠do com sucesso,Conclu√≠do sem sucesso,Recebido.'
                        'o campo id companhia possuem estes valores: TIM,LIGGA,SPEEDBOAT,PALLU,TEXNET,BWTELECOM,SOMA,FLIXF,Axxel,ASA,CLARO,LOVIZWH,Oi,EQUATORIAL,WLANFIBRA	
                        'indicador cumprimento agendamento instala√ß√£o no mes de maio:95%'
                        'indicador cumprimento agendamento instala√ß√£o no mes de abril: 94%'
                        'indicador cumprimento agendamento instala√ß√£o no mes de mar√ßo: 93%'
                        'indicador cumprimento agendamento instala√ß√£o no mes de fevereiro: 92%'
                        'indicador cumprimento agendamento instala√ß√£o no mes de janeiro: 91%'
                        'indicador cumprimento agendamento reparo no mes de janeiro: 81%'
                        'indicador cumprimento agendamento reparo no mes de fevereiro: 82%'
                        'indicador cumprimento agendamento reparo no mes de mar√ßo: 83%'
                        'indicador cumprimento agendamento reparo no mes de abril: 84%'
                        'indicador cumprimento agendamento reparo no mes de maio: 85%'
                        'indicador garantia no mes de janeiro: 71%'
                        'indicador garantia no mes de fevereiro: 72%'
                        'indicador garantia no mes de mar√ßo: 73%'
                        'indicador garantia no mes de abril: 74%'
                        'indicador garantia no mes de maio: 75%'



                        

                    """
        
        
        
        #melhor contexto
        contexto_1 = """
                        "O Brasil foi descoberto em 1500 por Pedro √Ålvares Cabral."
                        "Nesta √©poca, o Brasil era habitado por ind√≠genas."
                        "A primeira capital do Brasil foi Salvador, na Bahia."
                        "O Brasil √© o maior pa√≠s da Am√©rica do Sul."
                        "A l√≠ngua oficial do Brasil √© o portugu√™s."
                        "O Brasil √© conhecido por sua diversidade cultural e natural."
                        "O Brasil √© o lar da Floresta Amaz√¥nica, a maior floresta tropical do mundo."
                        "O Brasil √© famoso por seu carnaval, samba e futebol."
                        "O Brasil √© o maior produtor de caf√© do mundo."
                        "O Brasil tem uma rica hist√≥ria de coloniza√ß√£o e imigra√ß√£o."
                        "O Brasil √© o lar de v√°rias cidades ic√¥nicas, como Rio de Janeiro e S√£o Paulo."
                        "A m√©dia salarial no Brasil varia de acordo com a regi√£o e o setor."
                        "o brasileiro ganha em m√©dia R$ 2.500,00 por m√™s."
                        "O Brasil √© o maior pa√≠s da Am√©rica Latina."
                        "A capital do Brasil √© Bras√≠lia."
                        "A capital do Parana √© Curitiba."
                        "A capital do Rio de Janeiro √© a cidade do Rio de Janeiro."
                        "A capital de S√£o Paulo √© a cidade de S√£o Paulo."
                        "A capital do Rio Grande do Sul √© Porto Alegre."
                        "A capital do Rio Grande do Norte √© Natal."
                        "A capital do Cear√° √© Fortaleza."
                        "A capital do Maranh√£o √© S√£o Lu√≠s."
                        "A capital do Piau√≠ √© Teresina."
                        "A capital do Par√° √© Bel√©m."
                        "A capital do Amazonas √© Manaus."
                        "A capital do Acre √© Rio Branco."
                        "A capital de Roraima √© Boa Vista."
                        "A capital do Amap√° √© Macap√°."
                        "A capital do Tocantins √© Palmas."
                        "A capital do Maranh√£o √© S√£o Lu√≠s."
                        "A capital do Piau√≠ √© Teresina."
                        "A capital do Cear√° √© Fortaleza."
                        "A capital do Rio Grande do Norte √© Natal."
                        "A capital do Para√≠ba √© Jo√£o Pessoa."
                        "A capital de Pernambuco √© Recife."
                        "A capital do Alagoas √© Macei√≥."
                        "A capital de Sergipe √© Aracaju."
                        "A capital da Bahia √© Salvador."
                        "A capital do Esp√≠rito Santo √© Vit√≥ria."
                        "A capital de Minas Gerais √© Belo Horizonte."

                        """

        contexto_3 = """
                       'A Icomon √© uma empresa que presta servi√ßo na √°rea de telecomunica√ß√µes.
                        ela presta servi√ßos para estas empresas: Vtal, Oi, Vivo.
                        A icomon possui estes indicadores: agendamento,garantia.
                        Foi fundada em 2010.
                        Foi fundada por Elias Bragneto, Andr√© Aranha, Pedro Anizio, Marcelo Xives.
                        Possui sede em S√£o Paulo.
                        Possui filiais nestes estados: Paran√°, Rio de Janeiro, Rio Grande do Sul, Santa Catarina, Maranh√£o, Piau√≠.
                        A lucatividade no ano de 2022 foi de 10%, possibilitando um crescimento de 5% em rela√ß√£o ao ano de 2021.
                        Com isso, a icomon se tornou uma das maiores empresas de telecomunica√ß√µes do Brasil.Estamos projetando uma contrata√ß√£o de 150 colaboradores para o estado do Paran√°.
                        No mes de maio tivemos o resultado de 95% de cumprimento de agendamento de instala√ß√£o.

                    """
        
        
        #tokens = tokenizer.encode(contexto)
        #print("Total de tokens no contexto:", len(tokens))
        return contexto_file
    
    
    def load_model_roberta_large(self,user_input):
        contexto = self.contexto()
        model_name = "deepset/roberta-large-squad2"
        #print(f'no modelo {model_name}, vamos executar o seguinte contexto: {contexto}')
        from transformers import pipeline
        # a) Get predictions
        nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)
        QA_input = {
            'question': user_input,
            'context': contexto
                        
        
        
        }
        resposta_bot = nlp(QA_input)
        return resposta_bot['answer']

    
    def load_model_roberta_base(self,user_input):
        contexto = self.contexto()
        model_name = "deepset/roberta-base-squad2"
        #print(f'no modelo {model_name}, vamos executar o seguinte contexto: {contexto}')
        from transformers import pipeline
        # a) Get predictions
        nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)
        QA_input = {
            'question': user_input,
            'context': contexto
                        
        
        
        }
        resposta_bot = nlp(QA_input)
        return resposta_bot
      
    
    def load_model_long_former(self, user_input):
        import torch
        from transformers import AutoTokenizer, AutoModelForQuestionAnswering
        contexto = self.contexto()
        tokenizer = AutoTokenizer.from_pretrained("allenai/longformer-base-4096")
        model_name = "allenai/longformer-base-4096"
        model = AutoModelForQuestionAnswering.from_pretrained(model_name)
        #print(f'no modelo {model_name}, vamos executar o seguinte contexto: {contexto}')
        inputs = tokenizer(
            user_input,
            contexto,
            return_tensors="pt",
            truncation=True,
            max_length=4096
        )

        with torch.no_grad():
            outputs = model(**inputs)

        start = torch.argmax(outputs.start_logits)
        end = torch.argmax(outputs.end_logits) + 1

        resposta_bot = tokenizer.convert_tokens_to_string(
            tokenizer.convert_ids_to_tokens(inputs["input_ids"][0][start:end])
        )

        return resposta_bot
    
    
    def load_model_long_former_2(self, user_input):
        context = self.contexto()

        from transformers import AutoTokenizer, AutoModelForQuestionAnswering
        import torch

        # Modelo fine-tuned para SQuAD1
        model_name = "valhalla/longformer-base-4096-finetuned-squadv1"

        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForQuestionAnswering.from_pretrained(model_name)

        question = user_input
        #context = """
        #Longformer is a transformer model designed for long documents. 
        #It combines local and global attention patterns to efficiently process longer sequences. 
        #"""

        inputs = tokenizer(question, context, return_tensors="pt", max_length=4096, truncation=True)

        with torch.no_grad():
            outputs = model(**inputs)

        answer_start = torch.argmax(outputs.start_logits)
        answer_end = torch.argmax(outputs.end_logits) + 1

        answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs["input_ids"][0][answer_start:answer_end]))

        #print("Answer:", answer)
        return answer

    
    
    
    def streamlit(self):

       
        
        st.set_page_config(
            page_title="Chat bot Icomon",
            page_icon="üìä",
            layout="wide",  # Alternativas: 'centered' ou 'wide'
        )

        st.title("Chat bot Icomon")
        st.image(
                "ico.jpg",  # Caminho para a imagem
                width=100,
                #use_container_width=False,
            
            )
        st.write("Ol√°, sou um assistente virtual. Como posso ajudar voc√™ hoje?")
        user_input = st.text_input("Digite sua pergunta:")
       
        if "historico" not in st.session_state:
            st.session_state.historico = []
        
        
    
        if st.button("Enviar") and user_input.strip() != "":

           

            #resposta_bot = self.load_model_roberta(user_input)
            resposta_bot = self.load_model_roberta_large(user_input)
        
            

            # Armazena no hist√≥rico
            st.session_state.historico.append(("Voc√™", user_input))
            st.session_state.historico.append(("Bot", resposta_bot))

        # Exibe o hist√≥rico
        st.markdown("### Conversa:")
        for remetente, texto in st.session_state.historico:
            if remetente == "Voc√™":
                st.markdown(f"**üßë {remetente}:** {texto}")
            else:
                st.markdown(f"**ü§ñ {remetente}:** {texto}")
        
        
       

def main():
   
    
   
    execute = Oracle()
    #set_execute = input('Digite 1 para executar streamlit.Digite 2 para executar modelo roberta large.Digite 3 para executar modelo roberta base,digite 4 para carregar o modelo longformer, digite 4 para verificar contexto: ')
    
    execute.streamlit()

if __name__ == '__main__':
    main()



    










